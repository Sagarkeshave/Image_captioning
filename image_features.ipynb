{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyP9AdT3KOBcHjg76HyGj7w1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"UGwZ7oPxazxU"},"outputs":[],"source":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VJjzOpm1a_IX","executionInfo":{"status":"ok","timestamp":1700829688340,"user_tz":-330,"elapsed":21759,"user":{"displayName":"Sagar Keshave","userId":"06645747933422294441"}},"outputId":"41bc7073-12ed-4659-ad6d-876eebd34798"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils import shuffle\n","import os\n","import time\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n","import json\n","from glob import glob\n","from PIL import Image\n","import pickle\n","import random"],"metadata":{"id":"RA2G2IkAa_7c","executionInfo":{"status":"ok","timestamp":1700829695475,"user_tz":-330,"elapsed":2866,"user":{"displayName":"Sagar Keshave","userId":"06645747933422294441"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["### data\n","\n","!wget https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip\n","\n","!wget https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_text.zip\n","\n","\n","import zipfile\n","\n","def unzip_data(filename):\n","  \"\"\"\n","  Unzips filename into the current working directory.\n","\n","  Args:\n","    filename (str): a filepath to a target zip folder to be unzipped.\n","  \"\"\"\n","  zip_ref = zipfile.ZipFile(filename, \"r\")\n","  zip_ref.extractall()\n","  zip_ref.close()\n","\n","\n","unzip_data(\"/content/Flickr8k_Dataset.zip\")\n","unzip_data(\"/content/Flickr8k_text.zip\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rm-boHlhdniK","executionInfo":{"status":"ok","timestamp":1700829707722,"user_tz":-330,"elapsed":12255,"user":{"displayName":"Sagar Keshave","userId":"06645747933422294441"}},"outputId":"273fb517-a379-4c37-f3e7-5fc67e6cb52b"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-11-24 12:41:36--  https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip\n","Resolving github.com (github.com)... 140.82.113.3\n","Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/124585957/47f52b80-3501-11e9-8f49-4515a2a3339b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231124%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231124T124136Z&X-Amz-Expires=300&X-Amz-Signature=d860cd25285b26e82c004ff95f3bb374ac9cf3dc8da9c2ba27583eae6f47f007&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=124585957&response-content-disposition=attachment%3B%20filename%3DFlickr8k_Dataset.zip&response-content-type=application%2Foctet-stream [following]\n","--2023-11-24 12:41:36--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/124585957/47f52b80-3501-11e9-8f49-4515a2a3339b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231124%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231124T124136Z&X-Amz-Expires=300&X-Amz-Signature=d860cd25285b26e82c004ff95f3bb374ac9cf3dc8da9c2ba27583eae6f47f007&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=124585957&response-content-disposition=attachment%3B%20filename%3DFlickr8k_Dataset.zip&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1115419746 (1.0G) [application/octet-stream]\n","Saving to: ‘Flickr8k_Dataset.zip’\n","\n","Flickr8k_Dataset.zi 100%[===================>]   1.04G   258MB/s    in 4.1s    \n","\n","2023-11-24 12:41:40 (258 MB/s) - ‘Flickr8k_Dataset.zip’ saved [1115419746/1115419746]\n","\n","--2023-11-24 12:41:41--  https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_text.zip\n","Resolving github.com (github.com)... 140.82.113.4\n","Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/124585957/47f52b80-3501-11e9-8d2e-dd69a21a4362?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231124%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231124T124141Z&X-Amz-Expires=300&X-Amz-Signature=c8022bb23f086de3fae575efa6c9643180e9e716b7becc4cfc8d3274b0d2b2c8&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=124585957&response-content-disposition=attachment%3B%20filename%3DFlickr8k_text.zip&response-content-type=application%2Foctet-stream [following]\n","--2023-11-24 12:41:41--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/124585957/47f52b80-3501-11e9-8d2e-dd69a21a4362?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231124%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231124T124141Z&X-Amz-Expires=300&X-Amz-Signature=c8022bb23f086de3fae575efa6c9643180e9e716b7becc4cfc8d3274b0d2b2c8&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=124585957&response-content-disposition=attachment%3B%20filename%3DFlickr8k_text.zip&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2340801 (2.2M) [application/octet-stream]\n","Saving to: ‘Flickr8k_text.zip’\n","\n","Flickr8k_text.zip   100%[===================>]   2.23M  --.-KB/s    in 0.07s   \n","\n","2023-11-24 12:41:42 (29.9 MB/s) - ‘Flickr8k_text.zip’ saved [2340801/2340801]\n","\n"]}]},{"cell_type":"code","source":["image_path = \"/content/Flicker8k_Dataset\"\n","feat_path = \"/content/drive/MyDrive/deep_learning_projects/Image_captioning/data/image_feat\"\n","text_path = \"/content/drive/MyDrive/deep_learning_projects/Image_captioning/data/captions.txt.zip\""],"metadata":{"id":"qkc-NRsafvwY","executionInfo":{"status":"ok","timestamp":1700829707722,"user_tz":-330,"elapsed":4,"user":{"displayName":"Sagar Keshave","userId":"06645747933422294441"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv(text_path, skipinitialspace=True)\n","df.shape"],"metadata":{"id":"JC6wyDj2g9T8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700829708392,"user_tz":-330,"elapsed":673,"user":{"displayName":"Sagar Keshave","userId":"06645747933422294441"}},"outputId":"6dd85f2a-0c62-42c8-efb4-c1ca0de0de74"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(40455, 2)"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["8091*5"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6I6j3VXTCYis","executionInfo":{"status":"ok","timestamp":1700829708392,"user_tz":-330,"elapsed":18,"user":{"displayName":"Sagar Keshave","userId":"06645747933422294441"}},"outputId":"86731ec2-e852-4a60-ae88-89037b0b0d1b"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["40455"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["### each image has 4 - 5 captions for training"],"metadata":{"id":"ukeENvaHx2ul","executionInfo":{"status":"ok","timestamp":1700829708393,"user_tz":-330,"elapsed":17,"user":{"displayName":"Sagar Keshave","userId":"06645747933422294441"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["image_name_list = list(set(df['image'])) #obtaining unique instance name of each image\n","image_path_list = list(map(lambda arg: image_path + \"/\" + arg, image_name_list))\n","feat_path_list = list(map(lambda arg: feat_path + arg, image_name_list))\n","#Its imp to keep images and features in different directories so as to avoid Colab's infamous I/O error"],"metadata":{"id":"P1nIkGc6hBiE","executionInfo":{"status":"ok","timestamp":1700829708393,"user_tz":-330,"elapsed":16,"user":{"displayName":"Sagar Keshave","userId":"06645747933422294441"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["len(image_path_list)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jYW88vphwi4W","executionInfo":{"status":"ok","timestamp":1700829708393,"user_tz":-330,"elapsed":16,"user":{"displayName":"Sagar Keshave","userId":"06645747933422294441"}},"outputId":"bafe61a5-95f0-4b73-ad0d-3465372d5d6d"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["8091"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["image_path_list[:3]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"juu8eQq0w4Tz","executionInfo":{"status":"ok","timestamp":1700829708393,"user_tz":-330,"elapsed":14,"user":{"displayName":"Sagar Keshave","userId":"06645747933422294441"}},"outputId":"3db53f8f-22cb-4804-8e70-e3985faf2084"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['/content/Flicker8k_Dataset/2248487950_c62d0c81a9.jpg',\n"," '/content/Flicker8k_Dataset/3126795109_73920ed5dc.jpg',\n"," '/content/Flicker8k_Dataset/3542484764_77d8920ec9.jpg']"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["feat_path_list[:5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VwelVBSHw8rf","executionInfo":{"status":"ok","timestamp":1700829708394,"user_tz":-330,"elapsed":13,"user":{"displayName":"Sagar Keshave","userId":"06645747933422294441"}},"outputId":"761067b0-3f2b-43e2-abc1-266b8adc07fb"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['/content/drive/MyDrive/deep_learning_projects/Image_captioning/data/image_feat2248487950_c62d0c81a9.jpg',\n"," '/content/drive/MyDrive/deep_learning_projects/Image_captioning/data/image_feat3126795109_73920ed5dc.jpg',\n"," '/content/drive/MyDrive/deep_learning_projects/Image_captioning/data/image_feat3542484764_77d8920ec9.jpg',\n"," '/content/drive/MyDrive/deep_learning_projects/Image_captioning/data/image_feat745563422_f4fa7d9157.jpg',\n"," '/content/drive/MyDrive/deep_learning_projects/Image_captioning/data/image_feat2584020755_14e2b3e8fc.jpg']"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["def feat_extract():#Here we are performing surgery on a pretrained Inception V3 model so as to just obtain a model upto last conv layer\n","\n","  IV3 = tf.keras.applications.InceptionV3(include_top=False,weights='imagenet') #creating an inceptionV3 instance without last classification layer\n","\n","  x_in = IV3.input #we will feed input to the input layer of inception V3\n","  x_out= IV3.layers[-1].output #output of the last conv layer in inception V3 will will be taken as output\n","\n","  return tf.keras.Model(inputs=x_in, outputs=x_out) #Output will be of dimention 8*8*2048\n","\n","mod_fe = feat_extract()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y69KSKiuyCT-","executionInfo":{"status":"ok","timestamp":1700829715878,"user_tz":-330,"elapsed":6922,"user":{"displayName":"Sagar Keshave","userId":"06645747933422294441"}},"outputId":"e6f95854-c46b-4b1b-b01b-8c43330c77d1"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n","87910968/87910968 [==============================] - 1s 0us/step\n"]}]},{"cell_type":"code","source":["mod_fe.save('/content/drive/MyDrive/deep_learning_projects/Image_captioning/Models_/IV3_feat.h5') #saving because, we will also need it during evaluation\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5CLGVucRyXMv","executionInfo":{"status":"ok","timestamp":1700829717487,"user_tz":-330,"elapsed":1616,"user":{"displayName":"Sagar Keshave","userId":"06645747933422294441"}},"outputId":"80abaae0-4c97-4f7a-d4d9-c2a8bb25a93e"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]}]},{"cell_type":"markdown","source":["<!-- https://www.tensorflow.org/api_docs/python/tf/io/read_file\n","\n","`@tf.function\n","def load_image(filename):\n","  raw = tf.io.read_file(filename)\n","  image = tf.image.decode_png(raw, channels=3)\n","  // the `print` executes during tracing.\n","  print(\"Initial shape: \", image.shape)\n","  image.set_shape([28, 28, 3])\n","  print(\"Final shape: \", image.shape)\n","  return image` -->"],"metadata":{"id":"VEZottR_8fJk"}},{"cell_type":"code","source":["# @tf.function  from tensorflow\n","# def load_image(filename):\n","#   raw = tf.io.read_file(filename)\n","#   image = tf.image.decode_png(raw, channels=3)\n","#   # the `print` executes during tracing.\n","#   print(\"Initial shape: \", image.shape)\n","#   image.set_shape([28, 28, 3])\n","#   print(\"Final shape: \", image.shape)\n","#   return image"],"metadata":{"id":"jN3Yf0k69iW3","executionInfo":{"status":"ok","timestamp":1700829717487,"user_tz":-330,"elapsed":8,"user":{"displayName":"Sagar Keshave","userId":"06645747933422294441"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qOttVZZLFjfG","executionInfo":{"status":"ok","timestamp":1700829717488,"user_tz":-330,"elapsed":7,"user":{"displayName":"Sagar Keshave","userId":"06645747933422294441"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"gXHIOuLpFWdX","executionInfo":{"status":"ok","timestamp":1700829717488,"user_tz":-330,"elapsed":6,"user":{"displayName":"Sagar Keshave","userId":"06645747933422294441"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["def load_image(arg):\n","    img = tf.io.read_file(arg)\n","    img = tf.image.decode_jpeg(img, channels=3)\n","    img = tf.image.resize(img, (299, 299))\n","    img = tf.keras.applications.inception_v3.preprocess_input(img)\n","    return img, arg"],"metadata":{"id":"06UkiRevz8EB","executionInfo":{"status":"ok","timestamp":1700829718156,"user_tz":-330,"elapsed":674,"user":{"displayName":"Sagar Keshave","userId":"06645747933422294441"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["load_image(\"/content/Flicker8k_Dataset/1000268201_693b08cb0e.jpg\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s-u6kxDOFkj5","executionInfo":{"status":"ok","timestamp":1700829718157,"user_tz":-330,"elapsed":20,"user":{"displayName":"Sagar Keshave","userId":"06645747933422294441"}},"outputId":"4b56f480-e845-4ddb-9c9f-8465eab039c7"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(<tf.Tensor: shape=(299, 299, 3), dtype=float32, numpy=\n"," array([[[-5.4579198e-01, -5.1085913e-01, -3.7435186e-01],\n","         [-1.4921635e-01, -1.9675493e-04, -3.1106710e-02],\n","         [-9.7177267e-02,  4.6858430e-02,  4.3021560e-02],\n","         ...,\n","         [-9.7224247e-01, -9.6819955e-01, -9.8191810e-01],\n","         [-9.6078575e-01, -9.4020623e-01, -9.7377020e-01],\n","         [-9.6212077e-01, -9.3846858e-01, -9.8195148e-01]],\n"," \n","        [[-5.7653260e-01, -5.3617233e-01, -4.2858374e-01],\n","         [-1.4806336e-01,  5.8089495e-03, -5.5708170e-02],\n","         [-7.8158259e-02,  6.0893416e-02,  7.8846335e-02],\n","         ...,\n","         [-9.6420521e-01, -9.5636207e-01, -9.8523390e-01],\n","         [-9.3927324e-01, -9.2645574e-01, -9.5595336e-01],\n","         [-9.9189347e-01, -9.6899247e-01, -9.7989315e-01]],\n"," \n","        [[-5.9273523e-01, -5.6866682e-01, -4.3528360e-01],\n","         [-1.3315433e-01,  5.4714680e-03, -1.3691187e-02],\n","         [-8.0161095e-02,  5.6944609e-02,  1.0495746e-01],\n","         ...,\n","         [-9.5249414e-01, -9.2763758e-01, -9.5031697e-01],\n","         [-9.3824595e-01, -8.6041492e-01, -9.8345113e-01],\n","         [-8.2868659e-01, -6.7541003e-01, -9.5786130e-01]],\n"," \n","        ...,\n"," \n","        [[ 3.0902338e-01, -4.4748360e-01, -9.2698383e-01],\n","         [-2.7214885e-03, -4.9588060e-01, -9.2770636e-01],\n","         [ 9.6576571e-02, -3.8834935e-01, -7.3095071e-01],\n","         ...,\n","         [ 2.7618706e-01,  4.3293464e-01,  6.5229952e-01],\n","         [ 2.8129721e-01,  4.1696346e-01,  5.8506262e-01],\n","         [ 3.0553079e-01,  4.4718575e-01,  5.5857134e-01]],\n"," \n","        [[ 5.3182447e-01, -3.1337315e-01, -9.0544403e-01],\n","         [ 7.9157352e-01,  4.6837163e-01, -4.6576720e-01],\n","         [ 9.4054127e-01,  7.5203025e-01, -3.2983053e-01],\n","         ...,\n","         [ 2.7003217e-01,  4.3032777e-01,  6.3049579e-01],\n","         [ 2.9518056e-01,  4.2548299e-01,  5.7050514e-01],\n","         [ 3.2049739e-01,  4.5382237e-01,  5.2866936e-01]],\n"," \n","        [[ 5.4610419e-01, -1.9303948e-01, -7.5288111e-01],\n","         [ 6.3636053e-01,  6.1720252e-02, -5.8722854e-01],\n","         [ 1.5023518e-01, -4.2473215e-01, -7.3546636e-01],\n","         ...,\n","         [ 2.5475621e-01,  4.1562212e-01,  6.3599503e-01],\n","         [ 2.9489148e-01,  4.3242693e-01,  5.4649782e-01],\n","         [ 3.2538593e-01,  4.4574535e-01,  5.1968729e-01]]], dtype=float32)>,\n"," '/content/Flicker8k_Dataset/1000268201_693b08cb0e.jpg')"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["load_image('/content/Flicker8k_Dataset/825918657_d92f1761f4.jpg')     # as we set image path"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-o_d5lXsFxcx","executionInfo":{"status":"ok","timestamp":1700829718157,"user_tz":-330,"elapsed":18,"user":{"displayName":"Sagar Keshave","userId":"06645747933422294441"}},"outputId":"87890808-fe52-4769-fac0-b8ab9304f602"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(<tf.Tensor: shape=(299, 299, 3), dtype=float32, numpy=\n"," array([[[-0.9823393 , -0.65909445, -0.66317093],\n","         [-0.9985265 , -0.6822833 , -0.6846297 ],\n","         [-0.9928995 , -0.64420986, -0.6681721 ],\n","         ...,\n","         [-0.984732  , -0.6269039 , -0.64259017],\n","         [-0.9995672 , -0.64447635, -0.6679404 ],\n","         [-0.9969739 , -0.5883913 , -0.6249709 ]],\n"," \n","        [[-0.99220705, -0.68260443, -0.7178329 ],\n","         [-0.9740813 , -0.6201478 , -0.6657902 ],\n","         [-0.99516666, -0.66863716, -0.70650196],\n","         ...,\n","         [-0.9970799 , -0.645727  , -0.66182804],\n","         [-0.98313266, -0.5912047 , -0.6146796 ],\n","         [-0.9360738 , -0.50957596, -0.5474541 ]],\n"," \n","        [[-0.9805548 , -0.64826286, -0.726326  ],\n","         [-0.9717946 , -0.6304666 , -0.7088867 ],\n","         [-0.9788602 , -0.6351131 , -0.71219355],\n","         ...,\n","         [-0.99568063, -0.63441914, -0.6526107 ],\n","         [-0.93981105, -0.5434094 , -0.5690849 ],\n","         [-0.89458907, -0.44414598, -0.4907329 ]],\n"," \n","        ...,\n"," \n","        [[ 0.00785637,  0.12293279, -0.0836249 ],\n","         [-0.01641011,  0.14862359, -0.09477592],\n","         [-0.10064119,  0.10328031, -0.18190551],\n","         ...,\n","         [-0.12760603,  0.0351305 , -0.19035113],\n","         [-0.09673709,  0.08495212, -0.19059336],\n","         [-0.17806435,  0.0361681 , -0.3199032 ]],\n"," \n","        [[-0.05911839,  0.05595803, -0.15059984],\n","         [-0.09308034,  0.07195354, -0.17144614],\n","         [-0.1191178 ,  0.08480382, -0.20038211],\n","         ...,\n","         [-0.00148684,  0.17403233, -0.08413893],\n","         [-0.02096045,  0.19334447, -0.1148712 ],\n","         [-0.02489495,  0.21471846, -0.16386104]],\n"," \n","        [[-0.27003533, -0.1549589 , -0.3615167 ],\n","         [-0.40964884, -0.24461508, -0.48801464],\n","         [-0.20948291, -0.00556129, -0.29074717],\n","         ...,\n","         [-0.14765328,  0.02690303, -0.24701786],\n","         [-0.17522597,  0.04431295, -0.27643442],\n","         [-0.27124226, -0.00593871, -0.41470253]]], dtype=float32)>,\n"," '/content/Flicker8k_Dataset/825918657_d92f1761f4.jpg')"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["image_path_list[:3] ##"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ETMKppKr_Cuw","executionInfo":{"status":"ok","timestamp":1700829718157,"user_tz":-330,"elapsed":13,"user":{"displayName":"Sagar Keshave","userId":"06645747933422294441"}},"outputId":"b2a063c9-0cf3-4894-e6dd-155c7a48aa46"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['/content/Flicker8k_Dataset/2248487950_c62d0c81a9.jpg',\n"," '/content/Flicker8k_Dataset/3126795109_73920ed5dc.jpg',\n"," '/content/Flicker8k_Dataset/3542484764_77d8920ec9.jpg']"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["\n","\n","# image_dataset = tf.data.Dataset.from_tensor_slices(image_path_list)\n","\n","# image_dataset = image_dataset.map(load_image, num_parallel_calls=tf.data.AUTOTUNE) #this is a map() extention for \"Dataset\" type stucture  (https://www.tensorflow.org/guide/data_performance)\n","\n","# image_dataset = image_dataset.batch(32) #Since Inception V3 expects batch input anyways, so to leverage possible vectorization its better to send input in batches\n"],"metadata":{"id":"d77a9SOz5DAM","executionInfo":{"status":"ok","timestamp":1700829718157,"user_tz":-330,"elapsed":9,"user":{"displayName":"Sagar Keshave","userId":"06645747933422294441"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["#Features are being extracted seperately so as to avoid this part from becoming a bottleneck in further training\n","#Apart from this, features are cached in hard disk instead of RAM because of RAM's limitation in Collab\n","image_dataset = tf.data.Dataset.from_tensor_slices(image_path_list)\n","image_dataset = image_dataset.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE) #this is a map() extention for \"Dataset\" type stucture\n","image_dataset = image_dataset.batch(32) #Since Inception V3 expects batch input anyways, so to leverage possible vectorization its better to send input in batches\n","\n","for img, path in image_dataset:\n","  batch_features = mod_fe(img)\n","  batch_features = tf.reshape(batch_features,(batch_features.shape[0], 8*8, batch_features.shape[3]))\n","\n","  for bf, p in zip(batch_features, path):\n","    path_ = p.numpy().decode(\"utf-8\") #p is needed to be decoded as string becuase it is originally obtained as numpy object\n","    path_ = feat_path + path_[len(image_path):] # path_[len(image_path):] extracts name of image which is then concatenated to feature path\n","    np.save(path_, bf.numpy()) #saves feature matrix with same name as that of image\n","    #Feature matrix is of dim 64x2048"],"metadata":{"id":"iCZgsbII0By8","executionInfo":{"status":"ok","timestamp":1700830759932,"user_tz":-330,"elapsed":1041784,"user":{"displayName":"Sagar Keshave","userId":"06645747933422294441"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["#verifying quantity\n","import os, os.path\n","path = '/content/drive/MyDrive/deep_learning_projects/Image_captioning/data/image_feat'\n","num_files = len([f for f in os.listdir(path)if os.path.isfile(os.path.join(path, f))])\n","\n","num_files"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KAz6fs0v0upC","executionInfo":{"status":"ok","timestamp":1700830786372,"user_tz":-330,"elapsed":1326,"user":{"displayName":"Sagar Keshave","userId":"06645747933422294441"}},"outputId":"94621397-768d-461e-c12f-36bff106f238"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["8091"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":[],"metadata":{"id":"4_viZqyMTYg6","executionInfo":{"status":"aborted","timestamp":1700830760699,"user_tz":-330,"elapsed":17,"user":{"displayName":"Sagar Keshave","userId":"06645747933422294441"}}},"execution_count":null,"outputs":[]}]}